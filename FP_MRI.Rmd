---
title: "STA437 Final Project"
date: "2025-03-26"
output: html_document
---

# {.tabset}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(knitr)
library(kableExtra)
library(tidyverse)
library(lme4)        # For mixed-effects models
library(ggplot2)     # For visualization
library(reshape2)    # For matrix reshaping
library(igraph)      # For network analysis
library(corrplot)    # For correlation visualization
library(ggrepel)  # For avoiding label overlap
library(MASS)     # For classical MDS
library(CCA)       # For canonical correlation
library(yacca)     # Alternative CCA package (optional)
library(CCP)
library(abind)
library(pls)
library(PMA)
library(caret)     # For classification and performance metrics
library(e1071)

load("~/Desktop/Fourth Year/STA437/ABIDE_YALE.RData")


dem_mri <- YALE_demo_var

dem_mri$SubjectID <- 1:nrow(dem_mri)
str(dem_mri)
dem_mri$sexnum <- as.numeric(dem_mri$SEX)
```

## Demographic table

```{r}
# Compute summary by DX_GROUP
demographic_table <- dem_mri %>%
  group_by(DX_GROUP) %>%
  summarise(
    N = n(),
    `Mean Age (SD)` = sprintf("%.2f (%.2f)", mean(AGE_AT_SCAN, na.rm = TRUE), sd(AGE_AT_SCAN, na.rm = TRUE)),
    `Male (%)` = sprintf("%d (%.1f%%)", sum(SEX == "1"), 100 * mean(SEX == "1")),
    `Female (%)` = sprintf("%d (%.1f%%)", sum(SEX == "2"), 100 * mean(SEX == "2"))
  ) %>%
  rename(`Diagnosis Group` = DX_GROUP)

# Compute overall summary
overall_summary <- dem_mri %>%
  summarise(
    `Diagnosis Group` = "Overall",
    N = n(),
    `Mean Age (SD)` = sprintf("%.2f (%.2f)", mean(AGE_AT_SCAN, na.rm = TRUE), sd(AGE_AT_SCAN, na.rm = TRUE)),
    `Male (%)` = sprintf("%d (%.1f%%)", sum(SEX == "1"), 100 * mean(SEX == "1")),
    `Female (%)` = sprintf("%d (%.1f%%)", sum(SEX == "2"), 100 * mean(SEX == "2"))
  )

# Combine overall row with the grouped summary
final_table <- bind_rows(demographic_table, overall_summary)

# Print table using kable
kable(final_table, caption = "Demographic Characteristics", align = "c") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover"))
```


## PCA

```{r}
# Extract subject-level region-mean data 
region_mean_data <- sapply(YALE_fmri, function(mat) colMeans(mat, na.rm = TRUE))  # Compute mean for each region

# Transpose to have subjects as rows and regions as columns
region_mean_data <- t(region_mean_data)

# Standardize data (center and scale)
scaled_data <- scale(region_mean_data)

# Run PCA
pca_result <- prcomp(scaled_data, center = TRUE, scale. = TRUE)

# Print summary
summary(pca_result)



# Create a scree plot
scree_data <- data.frame(PC = seq_along(pca_result$sdev), 
                         Variance = (pca_result$sdev^2) / sum(pca_result$sdev^2))

ggplot(scree_data, aes(x = PC, y = Variance)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_line(aes(y = cumsum(Variance)), color = "red", group = 1) +
  labs(title = "Scree Plot", x = "Principal Components", y = "Proportion of Variance Explained") +
  theme_minimal()

# Extract loadings
loadings <- as.data.frame(pca_result$rotation)

# View top contributing regions for PC1 and PC2
top_PC1 <- loadings[order(abs(loadings$PC1), decreasing = TRUE), ][1:10, ]
top_PC2 <- loadings[order(abs(loadings$PC2), decreasing = TRUE), ][1:10, ]

print(top_PC1)
print(top_PC2)


# Create a dataframe for plotting
pca_scores <- data.frame(SubjectID = 1:nrow(region_mean_data),
                         PC1 = pca_result$x[,1],
                         PC2 = pca_result$x[,2],
                         DX_GROUP = dem_mri$DX_GROUP)

rownames(region_mean_data) <- names(YALE_fmri)  # Ensure subject IDs are correctly assigned
pca_scores <- data.frame(SubjectID = 1:nrow(region_mean_data),
                         PC1 = pca_result$x[,1],
                         PC2 = pca_result$x[,2])

# Check if the merge works
pca_scores <- merge(pca_scores, dem_mri[, c("SubjectID", "DX_GROUP")], by = "SubjectID", all.x = TRUE)

# Scatter plot of PC1 vs. PC2
ggplot(pca_scores, aes(x = PC1, y = PC2, color = as.factor(DX_GROUP))) +
  geom_point(alpha = 0.7) +
  labs(title = "PCA: PC1 vs. PC2", x = "PC1", y = "PC2", color = "Group") +
  theme_minimal() +
  scale_color_manual(values = c("red", "blue"), labels = c("Autism", "Control"))

scree_data <- data.frame(
  PC = seq_along(pca_result$sdev),
  Variance = (pca_result$sdev^2) / sum(pca_result$sdev^2)
)

ggplot(scree_data, aes(x = PC, y = Variance)) +
  geom_line(color = "steelblue", size = 1.2) +
  geom_point(linewidth = 2, color = "darkred") +
  scale_x_continuous(breaks = 1:20) +
  labs(title = "Scree Plot (Variance Explained)", 
       x = "Principal Component", 
       y = "Proportion of Variance Explained") +
  theme_minimal(base_size = 14)+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))


```

## MDS

```{r}
# Compute pairwise distances (Euclidean)
dist_matrix <- dist(scaled_data)  # Using pre-scaled data from PCA step

# Run MDS (classical/Kruskal's non-metric)
mds_result <- cmdscale(dist_matrix, k = 2, eig = TRUE)  # k=2 for 2D visualization

mds_scores <- data.frame(
  SubjectID = 1:nrow(region_mean_data),  # Replace with actual IDs if needed
  MDS1 = mds_result$points[, 1],
  MDS2 = mds_result$points[, 2],
  DX_GROUP = dem_mri$DX_GROUP,  # Diagnosis
  SEX = dem_mri$SEX,            # Sex (if available)
  AGE = dem_mri$AGE             # Age (if continuous/categorical)
)
mds_scores
ggplot(mds_scores, aes(x = MDS1, y = MDS2, color = DX_GROUP)) +
  geom_point(size = 3, alpha = 0.7) +
  geom_text_repel(aes(label = SubjectID), size = 3, max.overlaps = 20) +  # Optional labels
  scale_color_manual(values = c("1" = "#F8766D", "2" = "#00BFC4")) +
  labs(
    title = "MDS Plot of fMRI Data (Colored by Diagnosis)",
    x = "MDS Dimension 1",
    y = "MDS Dimension 2",
    color = "Group",
    levels = c("Autism", "Control"),
    breaks = c("Autism", "Control")
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

ggplot(mds_scores, aes(x = MDS1, y = MDS2, color = as.factor(DX_GROUP))) +
  geom_point(size = 3, alpha = 0.7) +
  stat_ellipse(type = "norm", level = 0.68) +  # 1 SD ellipse
  labs(title = "MDS Plot with Group Ellipses", x = "MDS1", y = "MDS2", color = "Group") +
  scale_color_manual(values = c("1" = "#F8766D", "2" = "#00BFC4"), labels = c("Autism", "Control")) +
  theme_minimal()



```


## CCA

```{r}

# Combine fMRI data
fmri_3d <- abind(YALE_fmri, along=3)  # Creates 196×110×47 array
region_mean_data <- t(apply(fmri_3d, c(2,3), mean))  # 47×110 matrix

age <- dem_mri$AGE_AT_SCAN

# PLS implementation
pls_model <- plsr(age ~ region_mean_data, ncomp=10, scale=TRUE)
X_cca <- pls_model$scores[,1:10]  # Extract scores

# Correct CCA function call
z_data <- dem_mri[, c("AGE_AT_SCAN", "sexnum")]  # Example variables

# Run CCA with multiple z variables
cca_result <- CCA(
  x = scale(X_cca),  # Brain data (47×10)
  z = scale(z_data), # Demographics (47×3)
  typex = "standard",
  typez = "standard",
  penaltyx = 0.3,
  penaltyz = 0.3,
  K = 1
)


perm_results <- CCA.permute(
  x=scale(X_cca),
  z=scale(z_data),
  penaltyxs=seq(0.1,0.5,length=5),
  nperms=1000
)

plot_data <- data.frame(
  Age = age,
  BrainScore = X_cca %*% cca_result$u,
  Group = dem_mri$DX_GROUP
)

ggplot(plot_data, aes(x=Age, y=BrainScore, color=Group)) +
  geom_point(size=3) +
  geom_smooth(method="lm") +
  labs(title=paste("CCA: r =", round(cca_result$cor,2)),
       subtitle=paste("p =", signif(perm_results$pvals[1],3)))
```

```{r}
library(abind)
# Stack the 196 region-by-110 matrices into a 3D array (196 x 110 x 47)
fmri_3d <- abind(YALE_fmri, along = 3)  # region x time x subject

# Compute region-mean for each subject: gives a 47 x 196 matrix
region_mean_data <- apply(fmri_3d, 3, function(x) colMeans(x, na.rm = TRUE))  # 110 x 47
region_mean_data <- t(region_mean_data)  # Subject (47) x Region (110)

library(pls)

# Extract number of subjects
n_subjects <- nrow(region_mean_data)

# Dimensionality reduction via PLS
pls_model <- plsr(dem_mri$AGE_AT_SCAN ~ region_mean_data, ncomp = 10, scale = TRUE)
X_cca <- pls_model$scores[, 1:10]  # Subject x 10 component matrix

# Choose relevant behavioral variables (standardized)
z_data <- scale(dem_mri[, c("AGE_AT_SCAN", "sexnum")])

library(PMA)

# Tune regularization parameters with permutations
set.seed(123)
perm_results <- CCA.permute(
  x = scale(X_cca),
  z = z_data,
  typex = "standard",
  typez = "standard",
  penaltyxs = seq(0.1, 0.5, length = 5),
  nperms = 1000
)

# Best penalties
penaltyx_opt <- perm_results$bestpenaltyx
penaltyz_opt <- perm_results$bestpenaltyz

# Run CCA with optimal penalties
cca_result <- CCA(
  x = scale(X_cca),
  z = z_data,
  typex = "standard",
  typez = "standard",
  penaltyx = penaltyx_opt,
  penaltyz = penaltyz_opt,
  K = 1
)

# Compute canonical variates (brain × behavior)
plot_data <- data.frame(
  Age = dem_mri$AGE_AT_SCAN,
  BrainScore = as.vector(scale(X_cca) %*% cca_result$u),
  BehaviorScore = as.vector(z_data %*% cca_result$v),
  Group = as.factor(dem_mri$DX_GROUP)
)

library(ggplot2)

# Joint correlation plot
ggplot(plot_data, aes(x = BrainScore, y = BehaviorScore, color = Group)) +
  geom_point(size = 3, alpha = 0.8) +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = paste0("CCA: r = ", round(cca_result$cor, 2),
                      ", p = ", signif(perm_results$pvals[1], 3)),
       x = "Canonical Variate (Brain)",
       y = "Canonical Variate (Behavior)") +
  scale_color_manual(values = c("1" = "#F8766D", "2" = "#00BFC4"),
                     labels = c("Autism", "Control")) +
  theme_minimal()

region_weights <- data.frame(
  Region = colnames(region_mean_data),
  Weight = cca_result$u[, 1]
)

top_regions <- region_weights[order(abs(region_weights$Weight), decreasing = TRUE), ][1:10, ]

ggplot(top_regions, aes(x = reorder(Region, Weight), y = Weight)) +
  geom_col(fill = "skyblue") +
  coord_flip() +
  labs(title = "Top Contributing Brain Regions to Canonical Variate",
       x = "Region",
       y = "Weight") +
  theme_minimal()

```


## UMAP

```{r}
library(umap)
# Extract features (exclude the Diagnosis column)
features <- classification_data %>% select(-Diagnosis)

# Labels (for coloring plots)
labels <- classification_data$Diagnosis

# Set UMAP configuration (customize hyperparameters if needed)
umap_config <- umap.defaults
umap_config$random_state <- 123  # For reproducibility
umap_config$n_neighbors <- 15    # Adjust based on data size (default=15)
umap_config$min_dist <- 0.1      # Controls cluster tightness (default=0.1)

# Run UMAP
umap_result <- umap(features, config = umap_config)

# Extract embeddings
umap_embeddings <- data.frame(
  UMAP1 = umap_result$layout[, 1],
  UMAP2 = umap_result$layout[, 2],
  Diagnosis = labels
)
# Plot UMAP with group ellipses (similar to your MDS plot)
ggplot(umap_embeddings, aes(x = UMAP1, y = UMAP2, color = Diagnosis)) +
  geom_point(size = 3, alpha = 0.7) +
  stat_ellipse(level = 0.95, linewidth = 1) +  # 95% confidence ellipses
  scale_color_manual(values = c("Autism" = "red", "Control" = "blue")) +
  labs(
    title = "UMAP Projection of fMRI Regional Activity",
    subtitle = "Colored by Diagnosis (95% Confidence Ellipses)",
    x = "UMAP Dimension 1",
    y = "UMAP Dimension 2"
  ) +
  theme_minimal()
```



## Classification






```{r}
library(caret)
library(randomForest)
library(tidyverse)

set.seed(37)

# Prepare data with meaningful class labels
classification_data <- data.frame(
  Diagnosis = factor(dem_mri$DX_GROUP,
                    levels = c(2, 1),
                    labels = c("Control", "Case")),
  region_mean_data
) %>% 
  na.omit() %>%
  # Remove near-zero variance features
  dplyr::select(-nearZeroVar(.))

# Check class distribution
cat("Class distribution:\n")
table(classification_data$Diagnosis)


# Set up control with cross-validation
ctrl <- trainControl(method = "cv",
                    number = 10,
                    savePredictions = TRUE,
                    classProbs = TRUE,
                    summaryFunction = twoClassSummary)

# Preprocessing steps (using your 27 PCA components)
preProc <- c("center", "scale", "pca")

### 1. SVM with Simplified Tuning ###
svm_grid <- expand.grid(
  sigma = c(0.01, 0.1, 1),  # Reasonable kernel widths
  C = c(0.1, 1, 10)         # Regularization parameters
)

svm_model <- train(
  Diagnosis ~ .,
  data = classification_data,
  method = "svmRadial",
  preProcess = preProc,
  trControl = ctrl,
  tuneGrid = svm_grid,
  metric = "ROC",  # Using AUC which balances sensitivity/specificity
  verbose = FALSE
)


### 2. Random Forest with Simplified Tuning ###
# Enhanced RF tuning
rf_grid <- expand.grid(
  mtry = c(3, 5, 7, 10, 15, 20),
  splitrule = c("gini", "extratrees"),
  min.node.size = c(1, 3, 5, 10)
)

# Increase number of trees
rf_model <- train(
  Diagnosis ~ .,
  data = classification_data,
  method = "ranger",
  preProcess = preProc,
  trControl = ctrl,
  tuneGrid = rf_grid,
  metric = "ROC",
  importance = "permutation",
  num.trees = 1000  # More trees for stability
)

### 3. Logistic Regression with Elastic Net ###
glmnet_grid <- expand.grid(
  alpha = seq(0, 1, by = 0.1),  # Finer alpha grid
  lambda = 10^seq(-4, 1, length = 20)  # Wider lambda range
)

glmnet_model <- train(
  Diagnosis ~ .,
  data = classification_data,
  method = "glmnet",
  preProcess = preProc,
  trControl = ctrl,
  tuneGrid = glmnet_grid,
  metric = "ROC"
)

### 4. XGBoost
xgb_grid <- expand.grid(
  nrounds = c(50, 100, 150),
  max_depth = c(3, 6, 9),
  eta = c(0.01, 0.1, 0.3),
  gamma = c(0, 0.1, 0.2),
  colsample_bytree = c(0.6, 0.8, 1),
  min_child_weight = c(1, 3, 5),
  subsample = c(0.5, 0.75, 1)
)

xgb_model <- train(
  Diagnosis ~ .,
  data = classification_data,
  method = "xgbTree",
  preProcess = preProc,
  trControl = ctrl,
  tuneGrid = xgb_grid,
  metric = "ROC",
  verbose = FALSE
)
### Performance Evaluation ###
results <- resamples(list(
  SVM = svm_model,
  RF = rf_model,
  GLMnet = glmnet_model,
  XGBoost = xgb_model
))

# Print summary metrics
summary(results)

# Custom function to print results
print_model_results <- function(model) {
  preds <- model$pred %>% 
    {if("bestTune" %in% names(model)) merge(., model$bestTune) else .} %>%
    arrange(rowIndex)
  
  cm <- confusionMatrix(preds$pred, preds$obs, positive = "Case")
  
  cat("\n=== ", model$method, "===\n")
  print(cm$table)
  cat("\nAccuracy:", round(cm$overall["Accuracy"], 3))
  cat(" | Sensitivity:", round(cm$byClass["Sensitivity"], 3))
  cat(" | Specificity:", round(cm$byClass["Specificity"], 3))
  cat(" | AUC:", round(max(model$results$ROC), 3), "\n")
}

# Print all results
print_model_results(svm_model)
print_model_results(rf_model)
print_model_results(glmnet_model)
print_model_results(xgb_model)

# Visualization
dotplot(results, metric = "ROC")

# Variable importance plots
ggplot(varImp(rf_model)) + ggtitle("Random Forest - Variable Importance")
ggplot(varImp(glmnet_model)) + ggtitle("GLMnet - Variable Importance")
```

